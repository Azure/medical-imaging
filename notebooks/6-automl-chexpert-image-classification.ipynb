{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Microsoft AI Rangers Demo\n",
        "# Large Scale Image Classification\n",
        "__X-Ray Classification using CheXpert__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"images/dp-chexpert.png\" width=800 />\n",
        "\n",
        "### Goal\n",
        "The goal of this notebook is demonstrate feasibility of large scale multi-label image classification from radiographs using the [Automated Machine Learning](https://learn.microsoft.com/en-us/azure/machine-learning/concept-automated-ml) feature of Azure Machine Learning. For this, we are using [CheXpert:](https://stanfordmlgroup.github.io/competitions/chexpert/) a large chest X-Ray dataset. Given that the original size of CheXpert is ~400GB, we will use the small version (images resized) which is ~11GB.\n",
        "\n",
        "\n",
        "### Steps\n",
        "1. Upload data (small dataset) to the cloud\n",
        "2. Convert the data to JSONL\n",
        "3. Set AutoML Run\n",
        "4. Configure parameters and run\n",
        "\n",
        "At the end, we show results using CheXpert standard image size (no resizing).\n",
        "\n",
        "This notebook was developed and tested using an Azure ML STANDARD_D13_V2 CPU [compute instance](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-manage-compute-instance?tabs=python) and an Azure ML [Python SDK v1](https://learn.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py&preserve-view=true).\n",
        "\n",
        "As with previous examples, having Azure account is a prerequisite. Once you have it, please set up an Azure ML Workspace and either create a new notebook or import this one there. You can follow official documentation for more details: https://learn.microsoft.com/en-us/azure/machine-learning/how-to-run-jupyter-notebooks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 1. Upload data to the cloud\n",
        "\n",
        "Since AutoML relies on AzureML experiment management infrastructure, we need to stage our data in the cloud first. \n",
        "\n",
        "## Download and extract CheXpert\n",
        "The dataset is available for download [here](https://stanfordmlgroup.github.io/competitions/chexpert/). After filling out the form you will receive an automated email from Stanford which will have a link to both full and downsampled dataset in it. We have downloaded the dataset from above url and unzipped the images files into the following structure:\n",
        "\n",
        "<img src=\"images/dp-chexpert-file-structure.png\" width=200 />\n",
        "\n",
        "Run the following cell (by replacing LINK_TO_FILE with the link you receive in the email) if you want to update and unzip automatically.\n",
        "\n",
        "> `NOTICE`: \n",
        "> Chexpert dataset contains images encoded as grayscale JPEGs. Since you are here, you probably know that real-world medical images come in DICOM format which is capable of much higher intensity range than what the 8bit grayscale that JPEG can provide is capable of. At the moment of writing, however, AutoML only supports the common 2D RGB image formats such as BMP, JPEG or PNG. You would have to convert your DICOMs into one of those, applying appropriate window width/window level transforms for best results. Unfortunately, if you are looking at working with 3D or 4D data such as CT, MR, fMRI, etc, you would either need to cast your task so that it can be inferred from independent 2D slices or use more advanced specialized frameworks such as Microsoft Research's [InnerEye Deep Learning SDK](https://github.com/microsoft/InnerEye-DeepLearning)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# remove files from /tmp to avoid potential overlap from previous runs\n",
        "!rm /tmp/CheXpert-v1.0-small.zip\n",
        "!rm -r /tmp/CheXpert-v1.0-small\n",
        "\n",
        "# Download the small version of the dataset\n",
        "!wget \"LINK_TO_FILE\" -P /tmp\n",
        "!unzip -q /tmp/CheXpert-v1.0-small.zip -d /tmp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Upload to blob storage\n",
        "\n",
        "You will be using Blob storage as the datastore in this example. Every Azure ML workspace will have a default datastore which the code below uses. You can pick a different datastore for your real-world scenario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.workspace import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "ds = ws.get_default_datastore()\n",
        "\n",
        "chexpert_local_path = '/tmp/CheXpert-v1.0-small/'\n",
        "blob_chexpert_target_name = \"chexpert_v1_small/\"\n",
        "\n",
        "# Upload image files to chexpert folder in AML datastore\n",
        "ds.upload(src_dir=chexpert_local_path, target_path=blob_chexpert_target_name, overwrite=True, show_progress=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 2. Convert the data to JSONL\n",
        "\n",
        "AutoML expects the mapping between data points and labels to be in a [JSONL format](https://jsonlines.org/). The following code will take in the training and validation CSVs provided by Chexpert and turn them into JSONL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(191027, 19)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Path</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Frontal/Lateral</th>\n",
              "      <th>AP/PA</th>\n",
              "      <th>No Finding</th>\n",
              "      <th>Enlarged Cardiomediastinum</th>\n",
              "      <th>Cardiomegaly</th>\n",
              "      <th>Lung Opacity</th>\n",
              "      <th>Lung Lesion</th>\n",
              "      <th>Edema</th>\n",
              "      <th>Consolidation</th>\n",
              "      <th>Pneumonia</th>\n",
              "      <th>Atelectasis</th>\n",
              "      <th>Pneumothorax</th>\n",
              "      <th>Pleural Effusion</th>\n",
              "      <th>Pleural Other</th>\n",
              "      <th>Fracture</th>\n",
              "      <th>Support Devices</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CheXpert-v1.0-small/train/patient00001/study1/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>68</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CheXpert-v1.0-small/train/patient00002/study2/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>87</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>83</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CheXpert-v1.0-small/train/patient00003/study1/...</td>\n",
              "      <td>Male</td>\n",
              "      <td>41</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Path     Sex  Age  \\\n",
              "0  CheXpert-v1.0-small/train/patient00001/study1/...  Female   68   \n",
              "1  CheXpert-v1.0-small/train/patient00002/study2/...  Female   87   \n",
              "2  CheXpert-v1.0-small/train/patient00002/study1/...  Female   83   \n",
              "4  CheXpert-v1.0-small/train/patient00003/study1/...    Male   41   \n",
              "\n",
              "  Frontal/Lateral AP/PA  No Finding  Enlarged Cardiomediastinum  Cardiomegaly  \\\n",
              "0         Frontal    AP         1.0                         NaN           NaN   \n",
              "1         Frontal    AP         NaN                         NaN          -1.0   \n",
              "2         Frontal    AP         NaN                         NaN           NaN   \n",
              "4         Frontal    AP         NaN                         NaN           NaN   \n",
              "\n",
              "   Lung Opacity  Lung Lesion  Edema  Consolidation  Pneumonia  Atelectasis  \\\n",
              "0           NaN          NaN    NaN            NaN        NaN          NaN   \n",
              "1           1.0          NaN   -1.0           -1.0        NaN         -1.0   \n",
              "2           1.0          NaN    NaN           -1.0        NaN          NaN   \n",
              "4           NaN          NaN    1.0            NaN        NaN          NaN   \n",
              "\n",
              "   Pneumothorax  Pleural Effusion  Pleural Other  Fracture  Support Devices  \n",
              "0           0.0               NaN            NaN       NaN              1.0  \n",
              "1           NaN              -1.0            NaN       1.0              NaN  \n",
              "2           NaN               NaN            NaN       1.0              NaN  \n",
              "4           0.0               NaN            NaN       NaN              NaN  "
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json, os\n",
        "\n",
        "df_train = pd.read_csv( chexpert_local_path + 'train.csv')\n",
        "df_train = df_train[df_train['Frontal/Lateral'] == 'Frontal']  \n",
        "\n",
        "df_valid = pd.read_csv(chexpert_local_path + 'valid.csv')\n",
        "df_valid = df_valid[df_valid['Frontal/Lateral'] == 'Frontal']  \n",
        "\n",
        "print(df_train.shape)\n",
        "df_train.head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "pathologies = ['Cardiomegaly', 'Edema', 'Consolidation', 'Atelectasis', 'Pleural Effusion']\n",
        "# sample json line dictionary\n",
        "json_line_sample = {\n",
        "    \"image_url\": \"AmlDatastore://\",\n",
        "    \"label\": \"\"\n",
        "    }\n",
        "\n",
        "chexpert_dataset_name = \"CheXpert-v1.0-small\"\n",
        "# To process standard CheXpert, just remove the '-small' characters:\n",
        "# chexpert_dataset_name = \"CheXpert-v1.0\"\n",
        "\n",
        "label_dir = 'label_files/'\n",
        "labels_chexpert_local_path = chexpert_local_path + label_dir\n",
        "\n",
        "if not os.path.exists(labels_chexpert_local_path):\n",
        "    os.mkdir(labels_chexpert_local_path)\n",
        "\n",
        "chexpert_train_jsonl_file_name = \"chexpert_train.jsonl\"\n",
        "chexpert_validation_jsonl_file_name = \"chexpert_validation.jsonl\"\n",
        "\n",
        "# Path to the training and validation files\n",
        "train_annotations_file = labels_chexpert_local_path + chexpert_train_jsonl_file_name\n",
        "validation_annotations_file = labels_chexpert_local_path + chexpert_validation_jsonl_file_name\n",
        "\n",
        "with open(train_annotations_file, \"w\") as train_f:\n",
        "    for idx, row in df_train.iterrows():\n",
        "        pathology_list = [pathology for pathology in pathologies if row[pathology] == 1]\n",
        "        if len(pathology_list) == 0:\n",
        "            pathology_list.append(\"X_other\")\n",
        "        json_line = dict(json_line_sample)\n",
        "        json_line[\"image_url\"] += \"workspaceblobstore/\" + row.Path.replace(chexpert_dataset_name,blob_chexpert_target_name) \n",
        "        json_line[\"label\"] = pathology_list  \n",
        "        train_f.write(json.dumps(json_line) + \"\\n\")\n",
        "\n",
        "with open(validation_annotations_file, \"w\") as validation_f:\n",
        "    for idx, row in df_valid.iterrows():\n",
        "        pathology_list = [pathology for pathology in pathologies if row[pathology] == 1]\n",
        "        if len(pathology_list) == 0:\n",
        "            pathology_list.append(\"X_other\")\n",
        "        json_line = dict(json_line_sample)\n",
        "        json_line[\"image_url\"] += \"workspaceblobstore/\" +  row.Path.replace(chexpert_dataset_name,blob_chexpert_target_name) \n",
        "        json_line[\"label\"] = pathology_list  \n",
        "        validation_f.write(json.dumps(json_line) + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uploading an estimated of 2 files\n",
            "Uploading /tmp/CheXpert-v1.0-small/label_files/chexpert_validation.jsonl\n",
            "Uploaded /tmp/CheXpert-v1.0-small/label_files/chexpert_validation.jsonl, 1 files out of an estimated total of 2\n",
            "Uploading /tmp/CheXpert-v1.0-small/label_files/chexpert_train.jsonl\n",
            "Uploaded /tmp/CheXpert-v1.0-small/label_files/chexpert_train.jsonl, 2 files out of an estimated total of 2\n",
            "Uploaded 2 files\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "$AZUREML_DATAREFERENCE_fe2c2f936a684cb6b4cd658e0e6acaf3"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds = ws.get_default_datastore()\n",
        "\n",
        "labels_chexpert_blob_path = blob_chexpert_target_name + label_dir\n",
        "\n",
        "# Upload json files to the label folder in AML datastore\n",
        "ds.upload(src_dir=labels_chexpert_local_path, target_path=labels_chexpert_blob_path, overwrite=True, show_progress=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code snippet below takes the JSONL files that were created just now and creates AzureML Dataset entities out of them, which is the mapping between the actual files and their labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training dataset name: chexpert_train\n",
            "Validation dataset name: chexpert_valid\n"
          ]
        }
      ],
      "source": [
        "from azureml.contrib.dataset.labeled_dataset import _LabeledDatasetFactory, LabeledDatasetTask\n",
        "from azureml.core import Dataset\n",
        "\n",
        "# Path to the training and validation files\n",
        "train_dataset_name = \"chexpert_train\"\n",
        "valid_dataset_name = \"chexpert_valid\"\n",
        "\n",
        "# create training dataset\n",
        "training_dataset = _LabeledDatasetFactory.from_json_lines(\n",
        "    task=LabeledDatasetTask.IMAGE_MULTI_LABEL_CLASSIFICATION, path=ds.path(labels_chexpert_blob_path + chexpert_train_jsonl_file_name))\n",
        "training_dataset = training_dataset.register(workspace=ws, name=train_dataset_name)\n",
        "\n",
        "# create validation dataset\n",
        "validation_dataset = _LabeledDatasetFactory.from_json_lines(\n",
        "    task=LabeledDatasetTask.IMAGE_MULTI_LABEL_CLASSIFICATION, path=ds.path(labels_chexpert_blob_path + chexpert_validation_jsonl_file_name))\n",
        "validation_dataset = validation_dataset.register(workspace=ws, name=valid_dataset_name)\n",
        "\n",
        "print(\"Training dataset name: \" + training_dataset.name)\n",
        "print(\"Validation dataset name: \" + validation_dataset.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_url</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>StreamInfo(AmlDatastore://workspaceblobstore/c...</td>\n",
              "      <td>[Cardiomegaly]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>StreamInfo(AmlDatastore://workspaceblobstore/c...</td>\n",
              "      <td>[X_other]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>StreamInfo(AmlDatastore://workspaceblobstore/c...</td>\n",
              "      <td>[Edema]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>StreamInfo(AmlDatastore://workspaceblobstore/c...</td>\n",
              "      <td>[X_other]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>StreamInfo(AmlDatastore://workspaceblobstore/c...</td>\n",
              "      <td>[Atelectasis, Pleural Effusion]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>StreamInfo(AmlDatastore://workspaceblobstore/c...</td>\n",
              "      <td>[Cardiomegaly, Atelectasis]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>StreamInfo(AmlDatastore://workspaceblobstore/c...</td>\n",
              "      <td>[X_other]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>StreamInfo(AmlDatastore://workspaceblobstore/c...</td>\n",
              "      <td>[X_other]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>StreamInfo(AmlDatastore://workspaceblobstore/c...</td>\n",
              "      <td>[Cardiomegaly, Consolidation, Atelectasis, Ple...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>StreamInfo(AmlDatastore://workspaceblobstore/c...</td>\n",
              "      <td>[Cardiomegaly]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           image_url  \\\n",
              "0  StreamInfo(AmlDatastore://workspaceblobstore/c...   \n",
              "1  StreamInfo(AmlDatastore://workspaceblobstore/c...   \n",
              "2  StreamInfo(AmlDatastore://workspaceblobstore/c...   \n",
              "3  StreamInfo(AmlDatastore://workspaceblobstore/c...   \n",
              "4  StreamInfo(AmlDatastore://workspaceblobstore/c...   \n",
              "5  StreamInfo(AmlDatastore://workspaceblobstore/c...   \n",
              "6  StreamInfo(AmlDatastore://workspaceblobstore/c...   \n",
              "7  StreamInfo(AmlDatastore://workspaceblobstore/c...   \n",
              "8  StreamInfo(AmlDatastore://workspaceblobstore/c...   \n",
              "9  StreamInfo(AmlDatastore://workspaceblobstore/c...   \n",
              "\n",
              "                                               label  \n",
              "0                                     [Cardiomegaly]  \n",
              "1                                          [X_other]  \n",
              "2                                            [Edema]  \n",
              "3                                          [X_other]  \n",
              "4                    [Atelectasis, Pleural Effusion]  \n",
              "5                        [Cardiomegaly, Atelectasis]  \n",
              "6                                          [X_other]  \n",
              "7                                          [X_other]  \n",
              "8  [Cardiomegaly, Consolidation, Atelectasis, Ple...  \n",
              "9                                     [Cardiomegaly]  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "validation_dataset.to_pandas_dataframe().head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Compute target setup\n",
        "You need to provide a [Compute Target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) that will be used for your AutoML model training. AutoML models for image tasks require GPU SKUs and support NC and ND families. We recommend using the NCsv3-series (with v100 GPUs) for faster training. Using a compute target with a multi-GPU VM SKU will leverage the multiple GPUs to speed up training. Additionally, setting up a compute target with multiple nodes will allow for faster model training by leveraging parallelism, when tuning hyperparameters for your model. See more on the compute targets in the official documentation: https://learn.microsoft.com/en-us/azure/machine-learning/concept-compute-target\n",
        "\n",
        "The code sample below creates a [low priority compute target](https://azure.microsoft.com/en-us/blog/low-priority-scale-sets/) which means that the Azure ML backend will look for underutilized resources across the datacenters and try to run your job on one of them. Being low priority resource means that your job may be pre-empted by some other job, i.e. the backend may have to restart it on another resource. However the upside is that a low priority resource comes at a fraction of a cost of a full system. In any case, AutoML will make sure that your powerful GPU machine will spend only as much time as needed working so that you don't have to pay for the compute you are not using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating a new compute target...\n",
            "InProgress..\n",
            "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "source": [
        "from azureml.core.compute import AmlCompute, ComputeTarget\n",
        "\n",
        "cluster_name = \"gpu-clu-nv24v3\"\n",
        "\n",
        "try:\n",
        "    compute_target = ws.compute_targets[cluster_name]\n",
        "    print('Found existing compute target.')\n",
        "except KeyError:\n",
        "    print('Creating a new compute target...')\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_NC6', \n",
        "                                                           vm_priority='lowpriority', # or 'dedicated\n",
        "                                                           idle_seconds_before_scaledown=1800,\n",
        "                                                           min_nodes=0, \n",
        "                                                           max_nodes=4)\n",
        "\n",
        "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "    \n",
        "# Can poll for a minimum number of nodes and for a specific timeout.\n",
        "# If no min_node_count is provided, it will use the scale settings for the cluster.\n",
        "compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Experiment\n",
        "\n",
        "experiment_name = \"automl-chexpert-classification-multilabel\"\n",
        "experiment = Experiment(ws, name=experiment_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "The key feature of AutoML is that it can sweep across a set of parameters selecting the combination that works best for your task. \n",
        "\n",
        "The configuration below uses Vision Transformer (ViT) model [vitb16r224](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models?tabs=cli#supported-model-algorithms) with image resize set to 256 and image center crop set to 224. To visualize performance for all epochs, we don't use an [early termination policy](https://learn.microsoft.com/en-us/azure/machine-learning/v1/how-to-auto-train-image-models-v1#early-termination-policies). In larger datasets and depending on the compute budget you can specify an early termination policy such as [Median stopping](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters#median-stopping-policy).\n",
        "\n",
        "You can modify this configuration by adding more models and parameters to try out. See reference here: https://learn.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.automl.core.shared.constants import ImageTask\n",
        "from azureml.train.automl import AutoMLImageConfig\n",
        "from azureml.train.hyperdrive import BanditPolicy, RandomParameterSampling,GridParameterSampling\n",
        "from azureml.train.hyperdrive import choice, uniform\n",
        "\n",
        "parameter_space = {\n",
        "    \"learning_rate\": choice(0.0001, .0003, .0005),\n",
        "    \"early_stopping\": choice(0),\n",
        "    \"weighted_loss\": choice(1,2),\n",
        "    \"number_of_epochs\": 10,\n",
        "    \"model\": choice(\n",
        "        {\n",
        "            # model-specific, valid_resize_size should be larger or equal than valid_crop_size\n",
        "            \"model_name\": choice(\"vitb16r224\"),            \n",
        "            \"valid_resize_size\": choice(256),\n",
        "            \"valid_crop_size\": choice(224),  # model-specific\n",
        "            \"train_crop_size\": choice(224),  # model-specific\n",
        "        }\n",
        "    ),\n",
        "}\n",
        "\n",
        "tuning_settings = {\n",
        "    \"iterations\": 6,\n",
        "    \"max_concurrent_iterations\": 4,\n",
        "    \"hyperparameter_sampling\": GridParameterSampling(parameter_space),\n",
        "    \"early_termination_policy\":None,\n",
        "}\n",
        "\n",
        "automl_image_config = AutoMLImageConfig(\n",
        "    task=ImageTask.IMAGE_CLASSIFICATION_MULTILABEL,\n",
        "    compute_target=compute_target,\n",
        "    training_data=training_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    **tuning_settings,\n",
        "    \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Kick off the experiment and put those GPUs to work!\n",
        "automl_image_run = experiment.submit(automl_image_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Visualize the different configurations that were tried using the HyperDrive UI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>automl-chexpert-classification-multilabel</td><td>AutoML_b7ae46a4-9972-468c-9aeb-18709b09e7f7_HD</td><td>hyperdrive</td><td>Completed</td><td><a href=\"https://ml.azure.com\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
            ],
            "text/plain": [
              "Run(Experiment: automl-chexpert-classification-multilabel,\n",
              "Id: AutoML_b7ae46a4-9972-468c-9aeb-18709b09e7f7_HD,\n",
              "Type: hyperdrive,\n",
              "Status: Completed)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azureml.core import Run\n",
        "hyperdrive_run = Run(experiment=experiment, run_id=automl_image_run.id + '_HD')\n",
        "hyperdrive_run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Download the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "best_child_run = run.get_best_child()\n",
        "model_name = best_child_run.properties['model_name']\n",
        "model = best_child_run.register_model(model_name = model_name, model_path='outputs/model.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Results using 'small CheXpert' dataset\n",
        "\n",
        "These are some of the charts from the experiments we have run when preparing this tutorial. You should get something similar.\n",
        "\n",
        "<img src=\"images/dp-chexpert_small-runs.png\" width=800 />\n",
        "\n",
        "<img src=\"images/dp-chexpert_small-runs_parallel_coordinates_chart.png\" width=800 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Bonus\n",
        "\n",
        "### Results using standard (non-resized) CheXpert dataset\n",
        "\n",
        "We show results of training CheXpert using the standard image size. The two graphs below show overall performance using a 'serexnet' model. In this case, we performed an exhaustive evaluation using by disabling the early terminal policy (configuration parameters are below). \n",
        "\n",
        "You can reproduce results by just downloading/unziping standard CheXpert dataset using the steps above and using the configuration settings below. \n",
        "\n",
        "<img src=\"images/dp-chexpert-runs.png\" width=800 >\n",
        "\n",
        "<img src=\"images/dp-chexpert-runs_parallel_coordinates_chart.png\" width=800 >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Effect of [hyperparameters](https://learn.microsoft.com/en-us/azure/machine-learning/reference-automl-images-hyperparameters#image-classification-multi-class-and-multi-label-specific-hyperparameters)\n",
        "\n",
        "We can easily visualize the effects of hyperparameters. The two graphs below show effect of learning rate and weighted loss with respect to the AUC macro (metric). Based on the graphs below, we osbserve that performance (AUC Macro) increases for:\n",
        "\n",
        "1. Larger learning rates (greater than 0.001) \n",
        "2. Weighted loss with sqrt. (class_weights), which corresponds to value 1 (value 2 corresponds to weighted loss with class_weights).\n",
        "\n",
        "<img src=\"images/dp-chexpert-scatter-AUC_lr.png\" width=800 >\n",
        "\n",
        "<img src=\"images/dp-chexpert-scatter-AUC_wl.png\" width=800 >\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## The parameter settings for the runs above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "parameter_space = {\n",
        "    \"learning_rate\": uniform(0.0005, 0.002), \n",
        "    \"early_stopping\": choice(0),\n",
        "    \"weighted_loss\": choice(1,2),\n",
        "    \"number_of_epochs\": 15,\n",
        "    \"model\": choice(\n",
        "\n",
        "        {\n",
        "            # model-specific, valid_resize_size should be larger or equal than valid_crop_size\n",
        "            \"model_name\": choice(\"seresnext\"),            \n",
        "            \"valid_resize_size\": choice(352),\n",
        "            \"valid_crop_size\": choice(256),  # model-specific\n",
        "            \"train_crop_size\": choice(256),  # model-specific\n",
        "            'training_batch_size': choice(48), \n",
        "            'validation_batch_size': choice(48),\n",
        "        }\n",
        "    ),\n",
        "}\n",
        "\n",
        "tuning_settings = {\n",
        "    \"iterations\": 20,\n",
        "    \"max_concurrent_iterations\": 8,\n",
        "    \"hyperparameter_sampling\": RandomParameterSampling(parameter_space),\n",
        "    \"early_termination_policy\":BanditPolicy(slack_factor = 0.4,\n",
        "                                         evaluation_interval = 1,\n",
        "                                         delay_evaluation = 5),\n",
        "}\n",
        "\n",
        "automl_image_config = AutoMLImageConfig(\n",
        "    task=ImageTask.IMAGE_CLASSIFICATION_MULTILABEL,\n",
        "    compute_target=compute_target,\n",
        "    training_data=training_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    **tuning_settings,\n",
        "    \n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion\n",
        "\n",
        "This tutorial has demonstrated the feasibility of low-code solution that is AutoML to achieve state-of-the-art performance on a radiological image classification task. Good luck with your experiments!"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3.7.6 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "715d590e6ff57b0722d0b838eec4a2f9adc9501372075d0cd25bc4f763d201c8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
