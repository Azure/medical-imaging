{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Microsoft AI Rangers Demo\n",
        "# Large Scale Image Classification\n",
        "__X-Ray Classification using CheXpert__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"images/dp-chexpert.png\" width=800 />\n",
        "\n",
        "### Goal\n",
        "The goal of this notebook is demonstrate feasiblity of large scale multi-label image classification from radiographs using Automated Machine Learning. For this, we are using [CheXpert:](https://stanfordmlgroup.github.io/competitions/chexpert/) a large chest X-Ray dataset. Given that the original size of CheXpert is ~400GB, we will use the small version (image resized) which is ~11GB.\n",
        "\n",
        "\n",
        "### Steps\n",
        "1. Upload data (small dataset) to the cloud\n",
        "2. Convert the data to JSONL\n",
        "3. Set AutoML Run\n",
        "4. Configure parameters and run\n",
        "\n",
        "At the end, we show results using CheXpert standard image size (no resizing).\n",
        "\n",
        "This notebook was developed and tested using an Azure ML STANDARD_D13_V2 CPU [compute instance](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-manage-compute-instance?tabs=python) and Python [SDK azureml v1](https://learn.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py&preserve-view=true).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 1. Upload data to the cloud\n",
        "\n",
        "## Download and extracting CheXpert\n",
        "The dataset is available for download [here](https://stanfordmlgroup.github.io/competitions/chexpert/). We have downloaded the dataset from above url and zipped the images files into the following structure:\n",
        "\n",
        "<img src=\"images/dp-chexpert-file-structure.png\" width=200 />\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# remove files from /tmp to avoid potential overlap from previous runs\n",
        "!rm /tmp/CheXpert-v1.0-small.zip\n",
        "!rm -r /tmp/CheXpert-v1.0-small\n",
        "\n",
        "# Download the small version of the dataset\n",
        "!wget \"LINK_TO_FILE\" -P /tmp\n",
        "!unzip -q /tmp/CheXpert-v1.0-small.zip -d /tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.workspace import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "ds = ws.get_default_datastore()\n",
        "\n",
        "chexpert_local_path = '/tmp/CheXpert-v1.0-small/'\n",
        "blob_chexpert_target_name = \"chexpert_v1_small/\"\n",
        "\n",
        "# Upload image files to livecell folder in AML datastore\n",
        "ds.upload(src_dir=chexpert_local_path, target_path=blob_chexpert_target_name, overwrite=True, show_progress=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 2. Convert the data to JSONL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(191027, 19)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Path</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Frontal/Lateral</th>\n",
              "      <th>AP/PA</th>\n",
              "      <th>No Finding</th>\n",
              "      <th>Enlarged Cardiomediastinum</th>\n",
              "      <th>Cardiomegaly</th>\n",
              "      <th>Lung Opacity</th>\n",
              "      <th>Lung Lesion</th>\n",
              "      <th>Edema</th>\n",
              "      <th>Consolidation</th>\n",
              "      <th>Pneumonia</th>\n",
              "      <th>Atelectasis</th>\n",
              "      <th>Pneumothorax</th>\n",
              "      <th>Pleural Effusion</th>\n",
              "      <th>Pleural Other</th>\n",
              "      <th>Fracture</th>\n",
              "      <th>Support Devices</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CheXpert-v1.0-small/train/patient00001/study1/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>68</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CheXpert-v1.0-small/train/patient00002/study2/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>87</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>83</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CheXpert-v1.0-small/train/patient00003/study1/...</td>\n",
              "      <td>Male</td>\n",
              "      <td>41</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Path     Sex  Age  \\\n",
              "0  CheXpert-v1.0-small/train/patient00001/study1/...  Female   68   \n",
              "1  CheXpert-v1.0-small/train/patient00002/study2/...  Female   87   \n",
              "2  CheXpert-v1.0-small/train/patient00002/study1/...  Female   83   \n",
              "4  CheXpert-v1.0-small/train/patient00003/study1/...    Male   41   \n",
              "\n",
              "  Frontal/Lateral AP/PA  No Finding  Enlarged Cardiomediastinum  Cardiomegaly  \\\n",
              "0         Frontal    AP         1.0                         NaN           NaN   \n",
              "1         Frontal    AP         NaN                         NaN          -1.0   \n",
              "2         Frontal    AP         NaN                         NaN           NaN   \n",
              "4         Frontal    AP         NaN                         NaN           NaN   \n",
              "\n",
              "   Lung Opacity  Lung Lesion  Edema  Consolidation  Pneumonia  Atelectasis  \\\n",
              "0           NaN          NaN    NaN            NaN        NaN          NaN   \n",
              "1           1.0          NaN   -1.0           -1.0        NaN         -1.0   \n",
              "2           1.0          NaN    NaN           -1.0        NaN          NaN   \n",
              "4           NaN          NaN    1.0            NaN        NaN          NaN   \n",
              "\n",
              "   Pneumothorax  Pleural Effusion  Pleural Other  Fracture  Support Devices  \n",
              "0           0.0               NaN            NaN       NaN              1.0  \n",
              "1           NaN              -1.0            NaN       1.0              NaN  \n",
              "2           NaN               NaN            NaN       1.0              NaN  \n",
              "4           0.0               NaN            NaN       NaN              NaN  "
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json, os\n",
        "\n",
        "df_train = pd.read_csv( chexpert_local_path + 'train.csv')\n",
        "df_train = df_train[df_train['Frontal/Lateral'] == 'Frontal']  \n",
        "\n",
        "df_valid = pd.read_csv(chexpert_local_path + 'valid.csv')\n",
        "df_valid = df_valid[df_valid['Frontal/Lateral'] == 'Frontal']  \n",
        "\n",
        "print(df_train.shape)\n",
        "df_train.head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "pathologies = ['Cardiomegaly', 'Edema', 'Consolidation', 'Atelectasis', 'Pleural Effusion']\n",
        "# sample json line dictionary\n",
        "json_line_sample = {\n",
        "    \"image_url\": \"AmlDatastore://\",\n",
        "    \"label\": \"\"\n",
        "    }\n",
        "\n",
        "chexpert_dataset_name = \"CheXpert-v1.0-small\"\n",
        "# To process standard CheXpert, just remove the '-small' characters:\n",
        "# chexpert_dataset_name = \"CheXpert-v1.0\"\n",
        "\n",
        "label_dir = 'label_files/'\n",
        "labels_chexpert_local_path = chexpert_local_path + label_dir\n",
        "\n",
        "if not os.path.exists(labels_chexpert_local_path):\n",
        "    os.mkdir(labels_chexpert_local_path)\n",
        "\n",
        "chexpert_train_jsonl_file_name = \"chexpert_train.jsonl\"\n",
        "chexpert_validation_jsonl_file_name = \"chexpert_validation.jsonl\"\n",
        "\n",
        "# Path to the training and validation files\n",
        "train_annotations_file = labels_chexpert_local_path + chexpert_train_jsonl_file_name\n",
        "validation_annotations_file = labels_chexpert_local_path + chexpert_validation_jsonl_file_name\n",
        "\n",
        "with open(train_annotations_file, \"w\") as train_f:\n",
        "    for idx, row in df_train.iterrows():\n",
        "        pathology_list = [pathology for pathology in pathologies if row[pathology] == 1]\n",
        "        if len(pathology_list) == 0:\n",
        "            pathology_list.append(\"X_other\")\n",
        "        json_line = dict(json_line_sample)\n",
        "        json_line[\"image_url\"] += \"workspaceblobstore/\" + row.Path.replace(chexpert_dataset_name,blob_chexpert_target_name) \n",
        "        json_line[\"label\"] = pathology_list  \n",
        "        train_f.write(json.dumps(json_line) + \"\\n\")\n",
        "\n",
        "with open(validation_annotations_file, \"w\") as validation_f:\n",
        "    for idx, row in df_valid.iterrows():\n",
        "        pathology_list = [pathology for pathology in pathologies if row[pathology] == 1]\n",
        "        if len(pathology_list) == 0:\n",
        "            pathology_list.append(\"X_other\")\n",
        "        json_line = dict(json_line_sample)\n",
        "        json_line[\"image_url\"] += \"workspaceblobstore/\" +  row.Path.replace(chexpert_dataset_name,blob_chexpert_target_name) \n",
        "        json_line[\"label\"] = pathology_list  \n",
        "        validation_f.write(json.dumps(json_line) + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uploading an estimated of 2 files\n",
            "Uploading /tmp/CheXpert-v1.0-small/label_files/chexpert_validation.jsonl\n",
            "Uploaded /tmp/CheXpert-v1.0-small/label_files/chexpert_validation.jsonl, 1 files out of an estimated total of 2\n",
            "Uploading /tmp/CheXpert-v1.0-small/label_files/chexpert_train.jsonl\n",
            "Uploaded /tmp/CheXpert-v1.0-small/label_files/chexpert_train.jsonl, 2 files out of an estimated total of 2\n",
            "Uploaded 2 files\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "$AZUREML_DATAREFERENCE_fe2c2f936a684cb6b4cd658e0e6acaf3"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds = ws.get_default_datastore()\n",
        "\n",
        "labels_chexpert_blob_path = blob_chexpert_target_name + label_dir\n",
        "\n",
        "# Upload json files to the label folder in AML datastore\n",
        "ds.upload(src_dir=labels_chexpert_local_path, target_path=labels_chexpert_blob_path, overwrite=True, show_progress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training dataset name: chexpert_train\n",
            "Validation dataset name: chexpert_valid\n"
          ]
        }
      ],
      "source": [
        "from azureml.contrib.dataset.labeled_dataset import _LabeledDatasetFactory, LabeledDatasetTask\n",
        "from azureml.core import Dataset\n",
        "\n",
        "# Path to the training and validation files\n",
        "train_dataset_name = \"chexpert_train\"\n",
        "valid_dataset_name = \"chexpert_valid\"\n",
        "\n",
        "# create training dataset\n",
        "training_dataset = _LabeledDatasetFactory.from_json_lines(\n",
        "    task=LabeledDatasetTask.IMAGE_MULTI_LABEL_CLASSIFICATION, path=ds.path(labels_chexpert_blob_path + chexpert_train_jsonl_file_name))\n",
        "training_dataset = training_dataset.register(workspace=ws, name=train_dataset_name)\n",
        "\n",
        "# create validation dataset\n",
        "validation_dataset = _LabeledDatasetFactory.from_json_lines(\n",
        "    task=LabeledDatasetTask.IMAGE_MULTI_LABEL_CLASSIFICATION, path=ds.path(labels_chexpert_blob_path + chexpert_validation_jsonl_file_name))\n",
        "validation_dataset = validation_dataset.register(workspace=ws, name=valid_dataset_name)\n",
        "\n",
        "print(\"Training dataset name: \" + training_dataset.name)\n",
        "print(\"Validation dataset name: \" + validation_dataset.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_url</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>StreamInfo(AmlDatastore://workspaceblobstore/c...</td>\n",
              "      <td>[Cardiomegaly]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>StreamInfo(AmlDatastore://workspaceblobstore/c...</td>\n",
              "      <td>[X_other]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>StreamInfo(AmlDatastore://workspaceblobstore/c...</td>\n",
              "      <td>[Edema]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>StreamInfo(AmlDatastore://workspaceblobstore/c...</td>\n",
              "      <td>[X_other]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>StreamInfo(AmlDatastore://workspaceblobstore/c...</td>\n",
              "      <td>[Atelectasis, Pleural Effusion]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>StreamInfo(AmlDatastore://workspaceblobstore/c...</td>\n",
              "      <td>[Cardiomegaly, Atelectasis]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>StreamInfo(AmlDatastore://workspaceblobstore/c...</td>\n",
              "      <td>[X_other]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>StreamInfo(AmlDatastore://workspaceblobstore/c...</td>\n",
              "      <td>[X_other]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>StreamInfo(AmlDatastore://workspaceblobstore/c...</td>\n",
              "      <td>[Cardiomegaly, Consolidation, Atelectasis, Ple...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>StreamInfo(AmlDatastore://workspaceblobstore/c...</td>\n",
              "      <td>[Cardiomegaly]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           image_url  \\\n",
              "0  StreamInfo(AmlDatastore://workspaceblobstore/c...   \n",
              "1  StreamInfo(AmlDatastore://workspaceblobstore/c...   \n",
              "2  StreamInfo(AmlDatastore://workspaceblobstore/c...   \n",
              "3  StreamInfo(AmlDatastore://workspaceblobstore/c...   \n",
              "4  StreamInfo(AmlDatastore://workspaceblobstore/c...   \n",
              "5  StreamInfo(AmlDatastore://workspaceblobstore/c...   \n",
              "6  StreamInfo(AmlDatastore://workspaceblobstore/c...   \n",
              "7  StreamInfo(AmlDatastore://workspaceblobstore/c...   \n",
              "8  StreamInfo(AmlDatastore://workspaceblobstore/c...   \n",
              "9  StreamInfo(AmlDatastore://workspaceblobstore/c...   \n",
              "\n",
              "                                               label  \n",
              "0                                     [Cardiomegaly]  \n",
              "1                                          [X_other]  \n",
              "2                                            [Edema]  \n",
              "3                                          [X_other]  \n",
              "4                    [Atelectasis, Pleural Effusion]  \n",
              "5                        [Cardiomegaly, Atelectasis]  \n",
              "6                                          [X_other]  \n",
              "7                                          [X_other]  \n",
              "8  [Cardiomegaly, Consolidation, Atelectasis, Ple...  \n",
              "9                                     [Cardiomegaly]  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "validation_dataset.to_pandas_dataframe().head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Compute target setup\n",
        "You need to provide a [Compute Target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) that will be used for your AutoML model training. AutoML models for image tasks require GPU SKUs and support NC and ND families. We recommend using the NCsv3-series (with v100 GPUs) for faster training. Using a compute target with a multi-GPU VM SKU will leverage the multiple GPUs to speed up training. Additionally, setting up a compute target with multiple nodes will allow for faster model training by leveraging parallelism, when tuning hyperparameters for your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating a new compute target...\n",
            "InProgress..\n",
            "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "source": [
        "from azureml.core.compute import AmlCompute, ComputeTarget\n",
        "\n",
        "cluster_name = \"gpu-clu-nv24v3\"\n",
        "\n",
        "try:\n",
        "    compute_target = ws.compute_targets[cluster_name]\n",
        "    print('Found existing compute target.')\n",
        "except KeyError:\n",
        "    print('Creating a new compute target...')\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_NC6', \n",
        "                                                           vm_priority='lowpriority', # or 'dedicated\n",
        "                                                           idle_seconds_before_scaledown=1800,\n",
        "                                                           min_nodes=0, \n",
        "                                                           max_nodes=4)\n",
        "\n",
        "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "    \n",
        "# Can poll for a minimum number of nodes and for a specific timeout.\n",
        "# If no min_node_count is provided, it will use the scale settings for the cluster.\n",
        "compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Experiment\n",
        "\n",
        "experiment_name = \"automl-chexpert-classification-multilabel\"\n",
        "experiment = Experiment(ws, name=experiment_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "We use the configuration below, using Vision Transformer (ViT) [vitb16r224](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models?tabs=cli#supported-model-algorithms) with image 256 image resize and 225 image center crop. To visualize performance for all epochs, we don't use an [early termination policy](https://learn.microsoft.com/en-us/azure/machine-learning/v1/how-to-auto-train-image-models-v1#early-termination-policies). In larger datasets and depending on the compute budget you can specify an early termination policy such as [Median stopping policy](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters#median-stopping-policy)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.automl.core.shared.constants import ImageTask\n",
        "from azureml.train.automl import AutoMLImageConfig\n",
        "from azureml.train.hyperdrive import BanditPolicy, RandomParameterSampling,GridParameterSampling\n",
        "from azureml.train.hyperdrive import choice, uniform\n",
        "\n",
        "parameter_space = {\n",
        "    \"learning_rate\": choice(0.0001, .0003, .0005),\n",
        "    \"early_stopping\": choice(0),\n",
        "    \"weighted_loss\": choice(1,2),\n",
        "    \"number_of_epochs\": 10,\n",
        "    \"model\": choice(\n",
        "        {\n",
        "            # model-specific, valid_resize_size should be larger or equal than valid_crop_size\n",
        "            \"model_name\": choice(\"vitb16r224\"),            \n",
        "            \"valid_resize_size\": choice(256),\n",
        "            \"valid_crop_size\": choice(224),  # model-specific\n",
        "            \"train_crop_size\": choice(224),  # model-specific\n",
        "        }\n",
        "    ),\n",
        "}\n",
        "\n",
        "tuning_settings = {\n",
        "    \"iterations\": 6,\n",
        "    \"max_concurrent_iterations\": 4,\n",
        "    \"hyperparameter_sampling\": GridParameterSampling(parameter_space),\n",
        "    \"early_termination_policy\":None,\n",
        "}\n",
        "\n",
        "automl_image_config = AutoMLImageConfig(\n",
        "    task=ImageTask.IMAGE_CLASSIFICATION_MULTILABEL,\n",
        "    compute_target=compute_target,\n",
        "    training_data=training_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    **tuning_settings,\n",
        "    \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "automl_image_run = experiment.submit(automl_image_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Visualize the different configurations that were tried using the HyperDrive UI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>automl-chexpert-classification-multilabel</td><td>AutoML_b7ae46a4-9972-468c-9aeb-18709b09e7f7_HD</td><td>hyperdrive</td><td>Completed</td><td><a href=\"https://ml.azure.com/runs/AutoML_b7ae46a4-9972-468c-9aeb-18709b09e7f7_HD?wsid=/subscriptions/6c180dd2-1ec4-4fad-8ba8-1f2d8d67c129/resourcegroups/opendataresearch/workspaces/automldemo&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
            ],
            "text/plain": [
              "Run(Experiment: automl-chexpert-classification-multilabel,\n",
              "Id: AutoML_b7ae46a4-9972-468c-9aeb-18709b09e7f7_HD,\n",
              "Type: hyperdrive,\n",
              "Status: Completed)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azureml.core import Run\n",
        "hyperdrive_run = Run(experiment=experiment, run_id=automl_image_run.id + '_HD')\n",
        "hyperdrive_run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Download the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "best_child_run = run.get_best_child()\n",
        "model_name = best_child_run.properties['model_name']\n",
        "model = best_child_run.register_model(model_name = model_name, model_path='outputs/model.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Results using 'small CheXpert' dataset\n",
        "\n",
        "<img src=\"images/dp-chexpert_small-runs.png\" width=800 />\n",
        "\n",
        "<img src=\"images/dp-chexpert_small-runs_parallel_coordinates_chart.png\" width=800 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Bonus\n",
        "\n",
        "### Results using standard (non-resized) CheXpert dataset\n",
        "\n",
        "We show results of training CheXpert using the standard image size. The two graphs below show overall performance using a 'serexnet' model. In this case, we performed an exaustive evaluation using by disabaling the early terminal policy (configuration parameters are below). \n",
        "\n",
        "You can reproduce results by just downloading/unziping standard CheXpert dataset using the steps above.\n",
        "\n",
        "<img src=\"images/dp-chexpert-runs.png\" width=800 >\n",
        "\n",
        "<img src=\"images/dp-chexpert-runs_parallel_coordinates_chart.png\" width=800 >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Effect of [hyperparameters](https://learn.microsoft.com/en-us/azure/machine-learning/reference-automl-images-hyperparameters#image-classification-multi-class-and-multi-label-specific-hyperparameters)\n",
        "\n",
        "We can easily visualize effects of hyperparameters. The two graphs below show effect of learning rate and weighted loss with respect to the AUC macro (metric). Based on the graphs below, we osbserve that performance (AUC Macro) increases for:\n",
        "\n",
        "1. Larger learning rates (greater than 0.001) \n",
        "2. Weighted loss with sqrt.(class_weights), which corresponds to value 1 (walue 2 corresponds to weighted loss with class_weights).\n",
        "\n",
        "<img src=\"images/dp-chexpert-scatter-AUC_lr.png\" width=800 >\n",
        "\n",
        "<img src=\"images/dp-chexpert-scatter-AUC_wl.png\" width=800 >\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## The parameter settings for the runs above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "parameter_space = {\n",
        "    \"learning_rate\": choice(0.0001, .0003, .0005),\n",
        "    \"early_stopping\": choice(0),\n",
        "    \"weighted_loss\": choice(1,2),\n",
        "    \"number_of_epochs\": 40,\n",
        "    \"model\": choice(\n",
        "        {\n",
        "            # model-specific, valid_resize_size should be larger or equal than valid_crop_size\n",
        "            \"model_name\": choice(\"seresnext\"),            \n",
        "            \"valid_resize_size\": choice(512),\n",
        "            \"valid_crop_size\": choice(488),  # model-specific\n",
        "            \"train_crop_size\": choice(488),  # model-specific\n",
        "            'training_batch_size': choice(48), \n",
        "            'validation_batch_size': choice(48)\n",
        "        },\n",
        "        {\n",
        "            # model-specific, valid_resize_size should be larger or equal than valid_crop_size\n",
        "            \"model_name\": choice(\"seresnext\"),            \n",
        "            \"valid_resize_size\": choice(288),\n",
        "            \"valid_crop_size\": choice(224),  # model-specific\n",
        "            \"train_crop_size\": choice(224),  # model-specific\n",
        "            'training_batch_size': choice(48), \n",
        "            'validation_batch_size': choice(48),\n",
        "        },\n",
        "        {\n",
        "            # model-specific, valid_resize_size should be larger or equal than valid_crop_size\n",
        "            \"model_name\": choice(\"seresnext\"),            \n",
        "            \"valid_resize_size\": choice(320),\n",
        "            \"valid_crop_size\": choice(224),  # model-specific\n",
        "            \"train_crop_size\": choice(224),  # model-specific\n",
        "            'training_batch_size': choice(48), \n",
        "            'validation_batch_size': choice(48),\n",
        "        },\n",
        "        {\n",
        "            # model-specific, valid_resize_size should be larger or equal than valid_crop_size\n",
        "            \"model_name\": choice(\"seresnext\"),            \n",
        "            \"valid_resize_size\": choice(352),\n",
        "            \"valid_crop_size\": choice(256),  # model-specific\n",
        "            \"train_crop_size\": choice(256),  # model-specific\n",
        "            'training_batch_size': choice(48), \n",
        "            'validation_batch_size': choice(48),\n",
        "        }\n",
        "    ),\n",
        "}\n",
        "\n",
        "tuning_settings = {\n",
        "    \"iterations\": 24,\n",
        "    \"max_concurrent_iterations\": 8,\n",
        "    \"hyperparameter_sampling\": GridParameterSampling(parameter_space),\n",
        "    \"early_termination_policy\":None,\n",
        "}\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "25b72a893ec4fee2ce5b3e05ac4135fcb8022615c60e71903276252789e8a937"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
